<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Python爬虫 实现从糗百上多线程抓取内容 &#8211; Lyfing.Loo's Blog</title>
<meta name="description" content="用Python写的爬虫，可以从糗百上抓取所有文章，并下载相关附图（如果附图的话）">
<meta name="keywords" content="Tech, Python, 多线程, 爬虫, 糗事百科, BeautifulSoup">



<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫 实现从糗百上多线程抓取内容">
<meta property="og:description" content="用Python写的爬虫，可以从糗百上抓取所有文章，并下载相关附图（如果附图的话）">
<meta property="og:url" content="http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html">
<meta property="og:site_name" content="Lyfing.Loo's Blog">





<link rel="canonical" href="http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Lyfing.Loo's Blog Feed">


<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.min.css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">




<style type="text/css">body {background-image:url(http://localhost:4000/images/ps_neutral.png);}</style>


</head>

<body id="post" class="feature" itemscope itemtype="http://schema.org/WebPage">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation" itemscope itemtype="http://schema.org/SiteNavigationElement">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://localhost:4000">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://localhost:4000/images/avatar.jpg" alt="Lyfing.Loo photo" class="author-photo">
					<h4>Lyfing.Loo</h4>
					<p>Hangzhou, China</p>
				</li>
				<li><a href="http://localhost:4000/about/">Learn More</a></li>
				<li>
					<a href="mailto:hellolyfing@gmail.com"><i class="icon-envelope"></i> Email</a>
				</li>
				
				
				
				
				
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://localhost:4000/archive/">All Posts</a></li>
				<li><a href="http://localhost:4000/tags/">All Tags</a></li>
			</ul>
		</li>
		
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->



<div class="entry-header">
  <div class="entry-image"><img src="http://localhost:4000/images/abstract-6.jpg" alt="Python爬虫 实现从糗百上多线程抓取内容" itemprop="image">
    <div class="image-credit">Image source: <a href="http://www.dargadgetz.com/ios-7-abstract-wallpaper-pack-for-iphone-5-and-ipod-touch-retina/">src</a></div><!-- /.image-credit -->
  </div><!-- /.entry-image -->
</div><!-- /.entry-header -->


<div id="main" role="main" itemprop="mainContentOfPage" itemscope itemtype="http://schema.org/Blog">
  <article class="hentry" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
    <header class="header-title">
      <div class="header-title-wrap">
        
          <h1 class="entry-title" itemprop="name"><a href="http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html" rel="bookmark" title="Python爬虫 实现从糗百上多线程抓取内容" itemprop="url">Python爬虫 实现从糗百上多线程抓取内容</a></h1>
        
        <h2>January 12, 2014</h2>
      </div><!-- /.header-title-wrap -->
    </header>
    <div class="entry-content" itemprop="description">
      <p>最近参加一家公司的远程笔试，其中的一道题目是：</p>

<blockquote>
  <p>写一个简单的爬虫，把糗事百科今天被顶超过5000的帖子爬出来，注意考虑性能和图片显示。</p>
</blockquote>

<p>当时一看很感兴趣，因为看到这道题目后思路很清晰，而且我大学时周围好友都爱看糗百，所以做点有关他们喜欢的产品的信息抓取还是挺有趣的。</p>

<p>好的，闲话就到这里，下面进入正题。</p>

<!--more-->

<h2 id="section">1. 思路</h2>

<h3 id="or-">1.1 单线程 or 多线程</h3>

<p><strong>单线程</strong>按序逐一抓取。这种思路下的实现方式是：</p>

<ol>
  <li>获取糗百所有可供抓取的页面URL，然后把他们放到一个列表里</li>
  <li>从列表中取走一条页面URL，将该URL指向页面中的所有糗百文章解析出来</li>
  <li>如果文章有附图，则下载至指定目录</li>
  <li>将第2步获得的若干糗百文章追加至一个xml文件中</li>
</ol>

<p>点评：单线程无法充分利用机器的CPU资源和带宽，性能低下，不予考虑</p>

<p><strong>多线程</strong>乱序抓取。这种思路下的实现方式是：</p>

<ol>
  <li>创建两个<a href="http://docs.python.org/2/library/queue.html">同步队列</a><code>page_q</code>和<code>pic_q</code>，<code>page_q</code>存放页面URL，<code>pic_q</code>存放图片URL</li>
  <li>获取糗百所有可供抓取页面的URL，将这些URL添加到<code>page_q</code>队列</li>
  <li>
    <p>开辟多条<strong>抓取解析页面文章的线程</strong>，每条线程的具体工作是：</p>

    <ul>
      <li>从<code>page_q</code>队列取走一条URL，解析其指向的页面中的糗百文章</li>
      <li>将这些文章内容追加到xml文件中(同步访问)</li>
      <li>如果文章有附图，则将该附图的链接URL放入<code>pic_q</code></li>
    </ul>
  </li>
  <li>
    <p>开辟多条<strong>下载图片的线程</strong>，每条线程的具体工作是：</p>

    <ul>
      <li>从<code>pic_q</code>队列取走一条图片URL，将其命名为<code>idxxxxx.jpg</code>并下载到指定目录 </li>
    </ul>
  </li>
</ol>

<p>点评：可以充分利用CPU资源及带宽，选择该条思路进行</p>

<h3 id="section-1">1.2 如何提取页面内容</h3>

<ul>
  <li>思路1：通过正则表达式匹配，然后提取有用信息</li>
  <li>思路2：通过第三方HTML内容提取工具提取有用信息</li>
</ul>

<p>点评：思路2具有更高的扩展性、容错性，选择思路2</p>

<h2 id="section-2">2. 实现</h2>

<h3 id="section-3">2.1 多线程实体</h3>

<p>本文设计了两个多线程类，他们都继承自<code>threading.Thread</code>，这两个类是：  </p>

<ul>
  <li><code>class QiubaiReader(threading.Thread)</code></li>
  <li><code>class PicDownloader(threading.Thread)</code></li>
</ul>

<p>类<code>QiubaiReader</code>要做的工作和本文第1部分 <strong>1.1</strong> » <strong>多线程</strong> » <strong>抓取解析页面文章的线程</strong>内容一致，以下是它的执行逻辑：</p>

<pre><code>""" 类 QiubaiReader 说明
糗事百科内容的消费者，也是糗事百科文章图片的生产者
消费者：从 pageQueue 里读取一个页面URL，解析该页面所有糗百文章，并将这些文章存储到xml文件中；
生产者：在解析页面时，如果某篇文章附带图片，则把该图片的URL放入 picQueue ,等待图片类的消费者来处理.
"""
runFlag = 1                                                    #停止线程的开关

def __init__(self, pageQueue, picQueue, pathDict):
    ...

def fetchContent(self, pageUrl):
    """
    每一条糗百，我们需要取出其中的三条信息：
    1. 该条糗百的ID
    2. 该条糗百的正文
    3. 该条糗百的图片链接(可能为空，非空则等待下载)
    爬取糗百的步骤是：
    1. 获得该条糗百的整个大&lt;div /&gt;块，我们声明 div_dad 变量代表这个大&lt;div /&gt;块
    2. 通过查找当前投票数的&lt;div /&gt;相关值来判断是否继续，如果投票数大于5000，则继续
    3. 在大&lt;div /&gt;块的首行，截取该条糗百的文章ID号（每条糗百都是一篇文章，通过文章ID可以获取文章和图片的链接）
    4. 在大div块中，找出带有糗百正文的&lt;div /&gt;块
    5. 将上面提到的三条信息写入xml文件
    """
    ...

def writeContent(self, list):
    """
    将list中包含的糗百文章格式化并一次性插入到xml文件中
    list中包含有某个页面的所有糗百文章（一般是20条）
    list结构为：
    [
        {   'id':       qiuID1,
            'content':  qiuBaiText,
            'picURL':   picURL },
        ...
    ]
    """
    ...

def run(self):
    while not self.pageQueue.empty() and self.__class__.runFlag &gt; 0:
        #糗百页面消费者
        pageUrl = self.pageQueue.get()
        qiuBaiList, picDictList = self.fetchContent(pageUrl)
        if len(qiuBaiList) &gt;= 1:
            self.writeContent(qiuBaiList)
        #糗百图片生产者
        if len(picDictList) &gt;= 1:
            for item in picDictList: self.picQueue.put(item)

    #如果两个队列都为空，则线程退出，并通知图片下载线程也退出
    if self.pageQueue.empty() and self.picQueue.empty():
        ...
</code></pre>

<p>类<code>PicDownloader</code>要做的工作和本文第1部分 <strong>1.1</strong> » <strong>多线程</strong> » <strong>下载图片的线程</strong>内容一致，以下是它的执行逻辑：</p>

<pre><code># 类 PicDownloader 说明
runFlag = 1                                                            #线程停止开关

def __init__(self, queue, pathDict):
    ...
def downloadPic(self, picDict):
    ...
def run(self):
    while self.__class__.runFlag &gt; 0:
        while not self.queue.empty():
            picDict = self.queue.get()
            self.downloadPic(picDict)
        time.sleep(1)                                                  #如果图片URL队列为空，则等待一秒
</code></pre>

<h3 id="section-4">2.2 线程安全队列</h3>

<p>本文涉及到的两个队列<code>page_q</code>和<code>pic_q</code>，一个用来存取页面URL，另一个用来存取图片URL，两队列都面临着多线程同步存取的问题，而这则是所有的”生产者-消费者问题”必须解决的问题。</p>

<p>幸运的是，我们用的是Python！  </p>

<p>Python已经为我们提供了一个线程安全队列：<a href="http://docs.python.org/2/library/queue.html">Queue</a>，它为多个”生产者-消费者”提供了安全同步队列。引用官方的一句话便是：</p>

<blockquote>
  <p>The <code>Queue</code> module implements multi-producer, multi-consumer queues. It is especially useful in threaded programming when information must be exchanged safely between multiple threads.</p>
</blockquote>

<p>而且<code>Queue</code>的创建、使用也极为轻便  <br />
创建</p>

<pre><code>import Queue
queue = Queue.Queue()
</code></pre>

<p>使用</p>

<pre><code>item_1 = queue.get()     # queue.get() =&gt; 从队列中移除一个item并返回该item
queue.put(item_2)        # queue.put() =&gt; 往队列中添加一个item
</code></pre>

<p>对<code>Queue</code>更高要求的操作与使用，请查看<a href="http://docs.python.org/2/library/queue.html">官方文档</a>。</p>

<h3 id="html">2.3 HTML内容提取</h3>

<p>该部分内容，其实是对类<code>QiubaiReader</code>中的<code>fetchContent(self, pageUrl)</code>方法的解读。从HTML中获取内容时，我们需要借助第三方开源工具<a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a>(看最下方应用程序信息)</p>

<p>为了便于升级改动，我们为类<code>QiubaiReader</code>声明一个类成员变量<code>argsDict</code>，用来统一糗事百科HTML页面源码中的一些关键性的标记及属性</p>

<pre><code>argsDict = {
        'pageEncoding'  : 'utf-8',                                 #糗百html的编码格式
        'dadClassAttr'  : 'block untagged mb15 bs2',               #某条糗百整个大&lt;div /&gt;块的class属性
        'contClassAttr' : 'content',                               #某条糗百的正文所在&lt;div /&gt;块的class属性
        'picClassAttr'  : 'thumb',                                 #包含图片的&lt;div /&gt;块的class属性
        'voteClassAttr' : 'bar',                                   #包含投票数的&lt;div /&gt;块的class属性
        #包含糗百ID的那一行的id号前的前缀，例如：'qiushi_tag_55611097'
        'idLinePreStr'  : 'qiushi_tag_',                           
        #某条糗百只有点赞数超过该值，才进行收录。题目要求该值为5000，本人感觉偏高，故将其改成了2000
        'validCountNum' : 2000,                                    
}
</code></pre>

<p>糗百每一个页面会包含20条糗百文章，读者可以<a href="https://code.csdn.net/snippets/156535/master/qiubai_content/raw">点此查看</a>其中某条糗百文章的HTML源码及其标记结构。</p>

<p>我们会发现糗百文章的HTML标记结构如下（我们姑且把如下<code>&lt;div /&gt;</code>块称作<code>文章的&lt;div /&gt;</code>块吧）：</p>

<pre><code>&lt;div class="block untagged mb15 bs2" id='qiushi_tag_idxxxxxx'&gt;
    &lt;div class="content" title="2014-01-14 16:33:29"&gt;
        糗百正文
    &lt;/div&gt;
    &lt;!--除非文章配有图片，否则下面这个div不会出现--&gt;
    &lt;div class="thumb"&gt;
        &lt;a href="/article/url..." target="_blank" onclick="some js"&gt;
            &lt;img src="http://the/pic/URL" alt="图片描述" /&gt;
        &lt;/a&gt;
    &lt;/div&gt;
&lt;/div&gt;
...
一个页面中会有20个上述结构出现，也就是20条糗百文章
...
</code></pre>

<p>以下的任务是，解析给定页面中的所有糗百文章，获取它们的点赞数、ID、正文以及图片链接（如果有的话）。这些解析工作需要借助<code>BeautifulSoup</code>工具来完成。</p>

<p><strong>step 1:</strong>我们首先引入<code>BeautifulSoup</code>，并实例化一个可操作的HTML结构体：</p>

<pre><code>import urllib2
from bs4 import BeautifulSoup
#获取给定页面pageURL的HTML源码
pageCont = urllib2.urlopen(pageURL).read().decode(self.argsDict['pageEncoding'])
#将HTML源码传递给BeautifulSoup，实例化一个它的对象
soup = BeautifulSoup(pageCont)
</code></pre>

<p><strong>step 2:</strong> 获得给定页面的所有20个上述的<code>文章&lt;div /&gt;</code>块</p>

<p>HTML是标记性语言，即使其中的<code>&lt;div&gt;</code>标记(tag)出现了很多次，而且分布杂乱，但我们可以根据一个<code>&lt;div&gt;</code>标记的多个属性来唯一确定某类/某个标记。
例如<code>文章&lt;div /&gt;</code>块的属性是：</p>

<pre><code>&lt;div class="block untagged mb15 bs2" id='qiushi_tag_idxxxxxx' &gt;&lt;/div&gt;
即：
class = "block untagged mb15 bs2"
id = "qiushi_tag_idxxxxxx"
</code></pre>

<p><code>文章&lt;div /&gt;</code>块的<code>id</code>属性不确定，但它的<code>class</code>属性是确定且唯一的，我们就使用它的<code>class</code>属性来找到这20个<code>文章&lt;div /&gt;</code>块，并把它们保存到一个<code>list</code>中</p>

<pre><code>articles_div_list = soup.find_all('div', attrs={'class': 'block untagged mb15 bs2'})
</code></pre>

<p><strong>step 3:</strong>接下来，我们遍历<code>articles_div_list</code>，并从中解析出我们需要的糗百信息</p>

<pre><code>for div_article in articles_div_list:
    ...
</code></pre>

<p>step 3.1 获得点赞数（<a href="https://code.csdn.net/snippets/156687/master/div_mark_vote/raw">点此查看</a>点赞内容所在<code>&lt;div&gt;</code>标记）</p>

<pre><code>div_vote = div_article.find('div', attrs={'class': 'bar'})  #用给定的属性键值对（class='bar')查找某个标记（tag）
upCount = div_vote.a.get_text()                      #通过 标记.字标记.get_text() 方法获得字标记的text
</code></pre>

<p>step 3.2 获得ID（<a href="https://code.csdn.net/snippets/156695/master/div_mark_id/raw">点此查看</a>ID内容所在<code>&lt;div&gt;</code>标记）</p>

<pre><code>idLine = div_article.attrs['id']  #想要获得某个标记（tag）的属性，可以直接查字典一样，此处key为某个属性的name
</code></pre>

<p>step 3.3 获得正文（<a href="https://code.csdn.net/snippets/156709/master/div_mark_cont/raw">点此查看</a>正文内容所在<code>&lt;div&gt;</code>标记）</p>

<pre><code>div_cont = div_article.find('div', attrs={'class': 'content'})
qiubai_cont = div_cont.get_text()                #通过标记的 get_text() 方法获得该标记的text
</code></pre>

<p>step 3.4 获得配图的URL（如果有的话。<a href="https://code.csdn.net/snippets/156693/master/div_mark_pic_url/raw">点此查看</a>配图URL内容所在<code>&lt;div&gt;</code>标记）</p>

<pre><code>div_pic = div_article.find('div', attrs={'class': 'thumb'})
if div_pic:
    #想要获得某个标记（tag）的子标记的子标记...的属性，可以直接通过 .(英文句点) 索引至该标记，然后像查字典一样查找即可
    picURL = div_pic.a.img['src']
</code></pre>

<h3 id="section-5">2.4 存储内容</h3>

<p>因为糗百内容要存储到xml文档中，我们在这里还要使用Python自带的操作XML的包：<code>xml.etree.ElementTree</code></p>

<p><strong>step 1：</strong>我们首先创建一个用于存储糗百的xml文档：</p>

<pre><code>fo = open('qiubai.xml', 'w')
fo.write('&lt;?xml version="1.0" encoding="utf-8"?&gt;\n&lt;ROOT&gt;&lt;/ROOT&gt;')
fo.close()
</code></pre>

<p>此时的xml文件看起来应该是这个样子：</p>

<pre><code>&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;ROOT&gt;
&lt;/ROOT&gt;
</code></pre>

<p><strong>step 2：</strong>给<code>qiubai.xml</code>添加一条糗百内容</p>

<p>step 2.1：获得<code>qiubai.xml</code>文档的根节点</p>

<pre><code>import xml.etree.ElementTree as ET
tree = ET.parse('qiubai.xml')       #也可以给 parse() 传递文档路径
root = tree.getroot()
</code></pre>

<p>step 2.2：为根节点<code>root</code>添加一个子节点<code>QiuBai</code>，并设置该子节点的各个属性</p>

<pre><code>qiubai = ET.SubElement(root, 'QiuBai')
qiubai.set('id', 'idxxxxxx')
qiubai.set('picURL', 'http://here/is/pic/url.jpg')
qiubai.text = '此处为糗百正文...'
</code></pre>

<p>step 2.3：将添加了新内容的<code>root</code>保存到文档</p>

<pre><code>tree = ET.ElementTree(root)
tree.write('qiubai.xml', encoding='utf-8', xml_declaration=True)
</code></pre>

<p>此时的xml文档看起来应该是这样子：</p>

<pre><code>&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;ROOT&gt;
    &lt;QiuBai id='idxxxxxx' picURL='http://here/is/pic/url.jpg'&gt;
        此处为糗百正文...
    &lt;/QiuBai&gt;
&lt;/ROOT&gt;
</code></pre>

<p>注意事项：如果你使用的是UTF-8格式保存xml文档，那你需要注意：xml文档规范并不支持所有的UTF-8支持的字符，也就是说有些UTF-8支持的字符在xml文档中是不受支持的，如果你坚持写入，则在再次读取xml文档是会出错。</p>

<p>关于过滤xml不支持字符的内容，请参看源码 <code>QiubaiReader.py</code> » <code>def replaceHellWord(text)</code>方法</p>

<h2 id="section-6">3. 源代码</h2>

<p>到<a href="https://github.com/HelloLyfing/Tiny_Projects/tree/master/WebSpider">这里</a>查看源码，或者直接<a href="https://github.com/HelloLyfing/Tiny_Projects/raw/master/WebSpider/web_spider.tar">点我</a>下载源码。</p>

<p>应用程序信息：</p>

<ul>
  <li>本程序在Window7平台下开发完成并测试通过；在CentOS 6.3下测试通过</li>
  <li>Python <code>2.7.5 [MSC v.1500 64 bit (AMD64)]</code></li>
  <li>
    <p>xml.etree.ElementTree <code>1.3.0</code> </p>

    <ul>
      <li>键入 <code>import xml.etree.ElementTree</code>； <code>ElementTree.VERSION</code> 查看</li>
    </ul>
  </li>
  <li>
    <p>Beautiful Soup <code>4.3.2</code>                           </p>

    <ul>
      <li>键入 <code>import bs4</code>；<code>bs4.__version__</code> </li>
      <li><a href="http://www.crummy.com/software/BeautifulSoup/bs4/download/4.3/">bs4下载链接</a></li>
    </ul>
  </li>
</ul>


      <footer class="entry-meta">
        <span class="entry-tags"><a href="http://localhost:4000/tags/index.html#Tech" title="Pages tagged Tech" rel="tag" class="tag">Tech</a><a href="http://localhost:4000/tags/index.html#Python" title="Pages tagged Python" rel="tag" class="tag">Python</a><a href="http://localhost:4000/tags/index.html#多线程" title="Pages tagged 多线程" rel="tag" class="tag">多线程</a><a href="http://localhost:4000/tags/index.html#爬虫" title="Pages tagged 爬虫" rel="tag" class="tag">爬虫</a><a href="http://localhost:4000/tags/index.html#糗事百科" title="Pages tagged 糗事百科" rel="tag" class="tag">糗事百科</a><a href="http://localhost:4000/tags/index.html#BeautifulSoup" title="Pages tagged BeautifulSoup" rel="tag" class="tag">BeautifulSoup</a></span>
        <span><a href="http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html" rel="bookmark" title="Python爬虫 实现从糗百上多线程抓取内容" itemprop="url">Python爬虫 实现从糗百上多线程抓取内容</a> was published on <span class="entry-date date published updated"><time datetime="2014-01-12T00:00:00+08:00" itemprop="datePublished">January 12, 2014</time></span></span>
        
        <span class="author vcard" itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name" class="fn"><a href="http://localhost:4000/about" title="About Lyfing.Loo" itemprop="url">Lyfing.Loo</a></span></span>
        <div class="social-share">
          <ul class="socialcount socialcount-small inline-list" data-url="http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html" data-share-text="Python爬虫 实现从糗百上多线程抓取内容">
            <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html" title="Share on Facebook"><span class="count"><i class="icon-facebook-sign"></i> Like</span></a></li>
            <li class="twitter"><a href="https://twitter.com/intent/tweet?text=http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html" title="Share on Twitter"><span class="count"><i class="icon-twitter-sign"></i> Tweet</span></a></li>
            <li class="googleplus"><a href="https://plus.google.com/share?url=http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html" title="Share on Google Plus"><span class="count"><i class="icon-google-plus-sign"></i> +1</span></a></li>
          </ul>
        </div><!-- /.social-share -->
      </footer>
    </div><!-- /.entry-content -->
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
    
    <div class="read-more">
      
        <div class="read-more-header">
          <a href="http://localhost:4000/2014/01/09/study-on-python-unicode-encoding-stuff.html" class="read-more-btn">Read More</a>
        </div><!-- /.read-more-header -->
        <div class="read-more-content">
          <h3><a href="http://localhost:4000/2014/06/28/upload-browser-cached-image-by-using-xhr.html" title="通过XHR上传浏览器缓存的图片资源">通过XHR上传浏览器缓存的图片资源</a></h3>
          <p>通过发起XHR请求的方式获取浏览器缓存的图片资源 <a href="http://localhost:4000/2014/06/28/upload-browser-cached-image-by-using-xhr.html">Continue reading</a></p>
        </div><!-- /.read-more-content -->
      
      <div class="read-more-list">
        
          <div class="list-item">
            <h4><a href="http://localhost:4000/2014/01/09/study-on-python-unicode-encoding-stuff.html" title="关于Python的编码、乱码以及Unicode的一些研究">关于Python的编码、乱码以及Unicode的一些研究</a></h4>
            <span>Published on January 09, 2014</span>
          </div><!-- /.list-item -->
        
          <div class="list-item">
            <h4><a href="http://localhost:4000/2013/10/20/Labwindows-tutorial-chapter3-part2.html" title="Labwindows.Tutorial.Chapter 3.Part2">Labwindows.Tutorial.Chapter 3.Part2</a></h4>
            <span>Published on October 20, 2013</span>
          </div><!-- /.list-item -->
        
      </div><!-- /.read-more-list -->
      
    </div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2014 Lyfing.Loo. Powered by <a href="http://jekyllrb.com">Jekyll</a> hosted on Github Pages using the <a href="https://github.com/mmistakes/hpstr-jekyll-theme">HPSTR Theme</a>.</span>

  </footer>
</div><!-- /.footer-wrapper -->

<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"></script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>

<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'lyfing521'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
	        

</body>
</html>
