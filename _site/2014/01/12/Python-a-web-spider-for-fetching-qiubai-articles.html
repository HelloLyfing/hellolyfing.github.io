<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Python爬虫 实现从糗百上多线程抓取内容 | Lyfing.Loo的技术博客</title>
<meta name="generator" content="Jekyll v3.6.2" />
<meta property="og:title" content="Python爬虫 实现从糗百上多线程抓取内容" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="用Python写的爬虫，可以从糗百上抓取所有文章，并下载相关附图（如果附图的话）" />
<meta property="og:description" content="用Python写的爬虫，可以从糗百上抓取所有文章，并下载相关附图（如果附图的话）" />
<link rel="canonical" href="http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html" />
<meta property="og:url" content="http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html" />
<meta property="og:site_name" content="Lyfing.Loo的技术博客" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2014-01-12T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"用Python写的爬虫，可以从糗百上抓取所有文章，并下载相关附图（如果附图的话）","url":"http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html","dateModified":"2014-01-12T00:00:00+08:00","datePublished":"2014-01-12T00:00:00+08:00","@type":"BlogPosting","headline":"Python爬虫 实现从糗百上多线程抓取内容","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Lyfing.Loo的技术博客" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Lyfing.Loo的技术博客</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Python爬虫 实现从糗百上多线程抓取内容</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2014-01-12T00:00:00+08:00" itemprop="datePublished">Jan 12, 2014
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>最近参加一家公司的远程笔试，其中的一道题目是：</p>

<blockquote>
  <p>写一个简单的爬虫，把糗事百科今天被顶超过5000的帖子爬出来，注意考虑性能和图片显示。</p>
</blockquote>

<p>当时一看很感兴趣，因为看到这道题目后思路很清晰，而且我大学时周围好友都爱看糗百，所以做点有关他们喜欢的产品的信息抓取还是挺有趣的。</p>

<p>好的，闲话就到这里，下面进入正题。</p>

<!--more-->

<h2 id="1-思路">1. 思路</h2>

<h3 id="11-单线程-or-多线程">1.1 单线程 or 多线程</h3>

<p><strong>单线程</strong>按序逐一抓取。这种思路下的实现方式是：</p>

<ol>
  <li>获取糗百所有可供抓取的页面URL，然后把他们放到一个列表里</li>
  <li>从列表中取走一条页面URL，将该URL指向页面中的所有糗百文章解析出来</li>
  <li>如果文章有附图，则下载至指定目录</li>
  <li>将第2步获得的若干糗百文章追加至一个xml文件中</li>
</ol>

<p>点评：单线程无法充分利用机器的CPU资源和带宽，性能低下，不予考虑</p>

<p><strong>多线程</strong>乱序抓取。这种思路下的实现方式是：</p>

<ol>
  <li>创建两个<a href="http://docs.python.org/2/library/queue.html">同步队列</a><code class="highlighter-rouge">page_q</code>和<code class="highlighter-rouge">pic_q</code>，<code class="highlighter-rouge">page_q</code>存放页面URL，<code class="highlighter-rouge">pic_q</code>存放图片URL</li>
  <li>获取糗百所有可供抓取页面的URL，将这些URL添加到<code class="highlighter-rouge">page_q</code>队列</li>
  <li>
    <p>开辟多条<strong>抓取解析页面文章的线程</strong>，每条线程的具体工作是：</p>

    <ul>
      <li>从<code class="highlighter-rouge">page_q</code>队列取走一条URL，解析其指向的页面中的糗百文章</li>
      <li>将这些文章内容追加到xml文件中(同步访问)</li>
      <li>如果文章有附图，则将该附图的链接URL放入<code class="highlighter-rouge">pic_q</code></li>
    </ul>
  </li>
  <li>
    <p>开辟多条<strong>下载图片的线程</strong>，每条线程的具体工作是：</p>

    <ul>
      <li>从<code class="highlighter-rouge">pic_q</code>队列取走一条图片URL，将其命名为<code class="highlighter-rouge">idxxxxx.jpg</code>并下载到指定目录</li>
    </ul>
  </li>
</ol>

<p>点评：可以充分利用CPU资源及带宽，选择该条思路进行</p>

<h3 id="12-如何提取页面内容">1.2 如何提取页面内容</h3>

<ul>
  <li>思路1：通过正则表达式匹配，然后提取有用信息</li>
  <li>思路2：通过第三方HTML内容提取工具提取有用信息</li>
</ul>

<p>点评：思路2具有更高的扩展性、容错性，选择思路2</p>

<h2 id="2-实现">2. 实现</h2>

<h3 id="21-多线程实体">2.1 多线程实体</h3>

<p>本文设计了两个多线程类，他们都继承自<code class="highlighter-rouge">threading.Thread</code>，这两个类是：</p>

<ul>
  <li><code class="highlighter-rouge">class QiubaiReader(threading.Thread)</code></li>
  <li><code class="highlighter-rouge">class PicDownloader(threading.Thread)</code></li>
</ul>

<p>类<code class="highlighter-rouge">QiubaiReader</code>要做的工作和本文第1部分 <strong>1.1</strong> » <strong>多线程</strong> » <strong>抓取解析页面文章的线程</strong>内容一致，以下是它的执行逻辑：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>""" 类 QiubaiReader 说明
糗事百科内容的消费者，也是糗事百科文章图片的生产者
消费者：从 pageQueue 里读取一个页面URL，解析该页面所有糗百文章，并将这些文章存储到xml文件中；
生产者：在解析页面时，如果某篇文章附带图片，则把该图片的URL放入 picQueue ,等待图片类的消费者来处理.
"""
runFlag = 1                                                    #停止线程的开关

def __init__(self, pageQueue, picQueue, pathDict):
    ...

def fetchContent(self, pageUrl):
    """
    每一条糗百，我们需要取出其中的三条信息：
    1. 该条糗百的ID
    2. 该条糗百的正文
    3. 该条糗百的图片链接(可能为空，非空则等待下载)
    爬取糗百的步骤是：
    1. 获得该条糗百的整个大&lt;div /&gt;块，我们声明 div_dad 变量代表这个大&lt;div /&gt;块
    2. 通过查找当前投票数的&lt;div /&gt;相关值来判断是否继续，如果投票数大于5000，则继续
    3. 在大&lt;div /&gt;块的首行，截取该条糗百的文章ID号（每条糗百都是一篇文章，通过文章ID可以获取文章和图片的链接）
    4. 在大div块中，找出带有糗百正文的&lt;div /&gt;块
    5. 将上面提到的三条信息写入xml文件
    """
    ...

def writeContent(self, list):
    """
    将list中包含的糗百文章格式化并一次性插入到xml文件中
    list中包含有某个页面的所有糗百文章（一般是20条）
    list结构为：
    [
        {   'id':       qiuID1,
            'content':  qiuBaiText,
            'picURL':   picURL },
        ...
    ]
    """
    ...

def run(self):
    while not self.pageQueue.empty() and self.__class__.runFlag &gt; 0:
        #糗百页面消费者
        pageUrl = self.pageQueue.get()
        qiuBaiList, picDictList = self.fetchContent(pageUrl)
        if len(qiuBaiList) &gt;= 1:
            self.writeContent(qiuBaiList)
        #糗百图片生产者
        if len(picDictList) &gt;= 1:
            for item in picDictList: self.picQueue.put(item)

    #如果两个队列都为空，则线程退出，并通知图片下载线程也退出
    if self.pageQueue.empty() and self.picQueue.empty():
        ...
</code></pre></div></div>

<p>类<code class="highlighter-rouge">PicDownloader</code>要做的工作和本文第1部分 <strong>1.1</strong> » <strong>多线程</strong> » <strong>下载图片的线程</strong>内容一致，以下是它的执行逻辑：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 类 PicDownloader 说明
runFlag = 1                                                            #线程停止开关

def __init__(self, queue, pathDict):
    ...
def downloadPic(self, picDict):
    ...
def run(self):
    while self.__class__.runFlag &gt; 0:
        while not self.queue.empty():
            picDict = self.queue.get()
            self.downloadPic(picDict)
        time.sleep(1)                                                  #如果图片URL队列为空，则等待一秒
</code></pre></div></div>

<h3 id="22-线程安全队列">2.2 线程安全队列</h3>

<p>本文涉及到的两个队列<code class="highlighter-rouge">page_q</code>和<code class="highlighter-rouge">pic_q</code>，一个用来存取页面URL，另一个用来存取图片URL，两队列都面临着多线程同步存取的问题，而这则是所有的”生产者-消费者问题”必须解决的问题。</p>

<p>幸运的是，我们用的是Python！</p>

<p>Python已经为我们提供了一个线程安全队列：<a href="http://docs.python.org/2/library/queue.html">Queue</a>，它为多个”生产者-消费者”提供了安全同步队列。引用官方的一句话便是：</p>

<blockquote>
  <p>The <code class="highlighter-rouge">Queue</code> module implements multi-producer, multi-consumer queues. It is especially useful in threaded programming when information must be exchanged safely between multiple threads.</p>
</blockquote>

<p>而且<code class="highlighter-rouge">Queue</code>的创建、使用也极为轻便  <br />
创建</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import Queue
queue = Queue.Queue()
</code></pre></div></div>

<p>使用</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>item_1 = queue.get()     # queue.get() =&gt; 从队列中移除一个item并返回该item
queue.put(item_2)        # queue.put() =&gt; 往队列中添加一个item
</code></pre></div></div>

<p>对<code class="highlighter-rouge">Queue</code>更高要求的操作与使用，请查看<a href="http://docs.python.org/2/library/queue.html">官方文档</a>。</p>

<h3 id="23-html内容提取">2.3 HTML内容提取</h3>

<p>该部分内容，其实是对类<code class="highlighter-rouge">QiubaiReader</code>中的<code class="highlighter-rouge">fetchContent(self, pageUrl)</code>方法的解读。从HTML中获取内容时，我们需要借助第三方开源工具<a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a>(看最下方应用程序信息)</p>

<p>为了便于升级改动，我们为类<code class="highlighter-rouge">QiubaiReader</code>声明一个类成员变量<code class="highlighter-rouge">argsDict</code>，用来统一糗事百科HTML页面源码中的一些关键性的标记及属性</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>argsDict = {
        'pageEncoding'  : 'utf-8',                                 #糗百html的编码格式
        'dadClassAttr'  : 'block untagged mb15 bs2',               #某条糗百整个大&lt;div /&gt;块的class属性
        'contClassAttr' : 'content',                               #某条糗百的正文所在&lt;div /&gt;块的class属性
        'picClassAttr'  : 'thumb',                                 #包含图片的&lt;div /&gt;块的class属性
        'voteClassAttr' : 'bar',                                   #包含投票数的&lt;div /&gt;块的class属性
        #包含糗百ID的那一行的id号前的前缀，例如：'qiushi_tag_55611097'
        'idLinePreStr'  : 'qiushi_tag_',                           
        #某条糗百只有点赞数超过该值，才进行收录。题目要求该值为5000，本人感觉偏高，故将其改成了2000
        'validCountNum' : 2000,                                    
}
</code></pre></div></div>

<p>糗百每一个页面会包含20条糗百文章，读者可以<a href="https://code.csdn.net/snippets/156535/master/qiubai_content/raw">点此查看</a>其中某条糗百文章的HTML源码及其标记结构。</p>

<p>我们会发现糗百文章的HTML标记结构如下（我们姑且把如下<code class="highlighter-rouge">&lt;div /&gt;</code>块称作<code class="highlighter-rouge">文章的&lt;div /&gt;</code>块吧）：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;div class="block untagged mb15 bs2" id='qiushi_tag_idxxxxxx'&gt;
    &lt;div class="content" title="2014-01-14 16:33:29"&gt;
        糗百正文
    &lt;/div&gt;
    &lt;!--除非文章配有图片，否则下面这个div不会出现--&gt;
    &lt;div class="thumb"&gt;
        &lt;a href="/article/url..." target="_blank" onclick="some js"&gt;
            &lt;img src="http://the/pic/URL" alt="图片描述" /&gt;
        &lt;/a&gt;
    &lt;/div&gt;
&lt;/div&gt;
...
一个页面中会有20个上述结构出现，也就是20条糗百文章
...
</code></pre></div></div>

<p>以下的任务是，解析给定页面中的所有糗百文章，获取它们的点赞数、ID、正文以及图片链接（如果有的话）。这些解析工作需要借助<code class="highlighter-rouge">BeautifulSoup</code>工具来完成。</p>

<p><strong>step 1:</strong>我们首先引入<code class="highlighter-rouge">BeautifulSoup</code>，并实例化一个可操作的HTML结构体：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import urllib2
from bs4 import BeautifulSoup
#获取给定页面pageURL的HTML源码
pageCont = urllib2.urlopen(pageURL).read().decode(self.argsDict['pageEncoding'])
#将HTML源码传递给BeautifulSoup，实例化一个它的对象
soup = BeautifulSoup(pageCont)
</code></pre></div></div>

<p><strong>step 2:</strong> 获得给定页面的所有20个上述的<code class="highlighter-rouge">文章&lt;div /&gt;</code>块</p>

<p>HTML是标记性语言，即使其中的<code class="highlighter-rouge">&lt;div&gt;</code>标记(tag)出现了很多次，而且分布杂乱，但我们可以根据一个<code class="highlighter-rouge">&lt;div&gt;</code>标记的多个属性来唯一确定某类/某个标记。
例如<code class="highlighter-rouge">文章&lt;div /&gt;</code>块的属性是：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;div class="block untagged mb15 bs2" id='qiushi_tag_idxxxxxx' &gt;&lt;/div&gt;
即：
class = "block untagged mb15 bs2"
id = "qiushi_tag_idxxxxxx"
</code></pre></div></div>

<p><code class="highlighter-rouge">文章&lt;div /&gt;</code>块的<code class="highlighter-rouge">id</code>属性不确定，但它的<code class="highlighter-rouge">class</code>属性是确定且唯一的，我们就使用它的<code class="highlighter-rouge">class</code>属性来找到这20个<code class="highlighter-rouge">文章&lt;div /&gt;</code>块，并把它们保存到一个<code class="highlighter-rouge">list</code>中</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>articles_div_list = soup.find_all('div', attrs={'class': 'block untagged mb15 bs2'})
</code></pre></div></div>

<p><strong>step 3:</strong>接下来，我们遍历<code class="highlighter-rouge">articles_div_list</code>，并从中解析出我们需要的糗百信息</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for div_article in articles_div_list:
    ...
</code></pre></div></div>

<p>step 3.1 获得点赞数（<a href="https://code.csdn.net/snippets/156687/master/div_mark_vote/raw">点此查看</a>点赞内容所在<code class="highlighter-rouge">&lt;div&gt;</code>标记）</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>div_vote = div_article.find('div', attrs={'class': 'bar'})  #用给定的属性键值对（class='bar')查找某个标记（tag）
upCount = div_vote.a.get_text()                      #通过 标记.字标记.get_text() 方法获得字标记的text
</code></pre></div></div>

<p>step 3.2 获得ID（<a href="https://code.csdn.net/snippets/156695/master/div_mark_id/raw">点此查看</a>ID内容所在<code class="highlighter-rouge">&lt;div&gt;</code>标记）</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>idLine = div_article.attrs['id']  #想要获得某个标记（tag）的属性，可以直接查字典一样，此处key为某个属性的name
</code></pre></div></div>

<p>step 3.3 获得正文（<a href="https://code.csdn.net/snippets/156709/master/div_mark_cont/raw">点此查看</a>正文内容所在<code class="highlighter-rouge">&lt;div&gt;</code>标记）</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>div_cont = div_article.find('div', attrs={'class': 'content'})
qiubai_cont = div_cont.get_text()                #通过标记的 get_text() 方法获得该标记的text
</code></pre></div></div>

<p>step 3.4 获得配图的URL（如果有的话。<a href="https://code.csdn.net/snippets/156693/master/div_mark_pic_url/raw">点此查看</a>配图URL内容所在<code class="highlighter-rouge">&lt;div&gt;</code>标记）</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>div_pic = div_article.find('div', attrs={'class': 'thumb'})
if div_pic:
    #想要获得某个标记（tag）的子标记的子标记...的属性，可以直接通过 .(英文句点) 索引至该标记，然后像查字典一样查找即可
    picURL = div_pic.a.img['src']
</code></pre></div></div>

<h3 id="24-存储内容">2.4 存储内容</h3>

<p>因为糗百内容要存储到xml文档中，我们在这里还要使用Python自带的操作XML的包：<code class="highlighter-rouge">xml.etree.ElementTree</code></p>

<p><strong>step 1：</strong>我们首先创建一个用于存储糗百的xml文档：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fo = open('qiubai.xml', 'w')
fo.write('&lt;?xml version="1.0" encoding="utf-8"?&gt;\n&lt;ROOT&gt;&lt;/ROOT&gt;')
fo.close()
</code></pre></div></div>

<p>此时的xml文件看起来应该是这个样子：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span class="nt">&lt;ROOT&gt;</span>
<span class="nt">&lt;/ROOT&gt;</span>
</code></pre></div></div>

<p><strong>step 2：</strong>给<code class="highlighter-rouge">qiubai.xml</code>添加一条糗百内容</p>

<p>step 2.1：获得<code class="highlighter-rouge">qiubai.xml</code>文档的根节点</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import xml.etree.ElementTree as ET
tree = ET.parse('qiubai.xml')       #也可以给 parse() 传递文档路径
root = tree.getroot()
</code></pre></div></div>

<p>step 2.2：为根节点<code class="highlighter-rouge">root</code>添加一个子节点<code class="highlighter-rouge">QiuBai</code>，并设置该子节点的各个属性</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>qiubai = ET.SubElement(root, 'QiuBai')
qiubai.set('id', 'idxxxxxx')
qiubai.set('picURL', 'http://here/is/pic/url.jpg')
qiubai.text = '此处为糗百正文...'
</code></pre></div></div>

<p>step 2.3：将添加了新内容的<code class="highlighter-rouge">root</code>保存到文档</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tree = ET.ElementTree(root)
tree.write('qiubai.xml', encoding='utf-8', xml_declaration=True)
</code></pre></div></div>

<p>此时的xml文档看起来应该是这样子：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span class="nt">&lt;ROOT&gt;</span>
    <span class="nt">&lt;QiuBai</span> <span class="na">id=</span><span class="s">'idxxxxxx'</span> <span class="na">picURL=</span><span class="s">'http://here/is/pic/url.jpg'</span><span class="nt">&gt;</span>
        此处为糗百正文...
    <span class="nt">&lt;/QiuBai&gt;</span>
<span class="nt">&lt;/ROOT&gt;</span>
</code></pre></div></div>

<p>注意事项：如果你使用的是UTF-8格式保存xml文档，那你需要注意：xml文档规范并不支持所有的UTF-8支持的字符，也就是说有些UTF-8支持的字符在xml文档中是不受支持的，如果你坚持写入，则在再次读取xml文档是会出错。</p>

<p>关于过滤xml不支持字符的内容，请参看源码 <code class="highlighter-rouge">QiubaiReader.py</code> » <code class="highlighter-rouge">def replaceHellWord(text)</code>方法</p>

<h2 id="3-源代码">3. 源代码</h2>

<p>到<a href="https://github.com/HelloLyfing/Tiny_Projects/tree/master/WebSpider">这里</a>查看源码，或者直接<a href="https://github.com/HelloLyfing/Tiny_Projects/raw/master/WebSpider/web_spider.tar">点我</a>下载源码。</p>

<p>应用程序信息：</p>

<ul>
  <li>本程序在Window7平台下开发完成并测试通过；在CentOS 6.3下测试通过</li>
  <li>Python <code class="highlighter-rouge">2.7.5 [MSC v.1500 64 bit (AMD64)]</code></li>
  <li>
    <p>xml.etree.ElementTree <code class="highlighter-rouge">1.3.0</code></p>

    <ul>
      <li>键入 <code class="highlighter-rouge">import xml.etree.ElementTree</code>； <code class="highlighter-rouge">ElementTree.VERSION</code> 查看</li>
    </ul>
  </li>
  <li>
    <p>Beautiful Soup <code class="highlighter-rouge">4.3.2</code></p>

    <ul>
      <li>键入 <code class="highlighter-rouge">import bs4</code>；<code class="highlighter-rouge">bs4.__version__</code></li>
      <li><a href="http://www.crummy.com/software/BeautifulSoup/bs4/download/4.3/">bs4下载链接</a></li>
    </ul>
  </li>
</ul>


  </div><a class="u-url" href="/2014/01/12/Python-a-web-spider-for-fetching-qiubai-articles.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Lyfing.Loo的技术博客</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Lyfing.Loo的技术博客</li><li><a class="u-email" href="mailto:"></a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>新浪微博@蓝枫铭</p>
      </div>
    </div>

  </div>

</footer>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1273259063'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s19.cnzz.com/z_stat.php%3Fid%3D1273259063%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script></body>

</html>
